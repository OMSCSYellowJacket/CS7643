{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "eps = 1e-8 #needed for numerical stability\n",
    "L = 756 #length of dataframe for date range of interest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitdata():\n",
    "    \"\"\"\n",
    "    Splits data into train, val, test for model development\n",
    "\n",
    "    Parameters:\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Delete CSV files in the folder\n",
    "    csv_files = glob.glob(os.path.join('model_data\\\\test_data\\\\', '*.csv'))\n",
    "    for file in csv_files:\n",
    "        os.remove(file)\n",
    "\n",
    "    csv_files = glob.glob(os.path.join('model_data\\\\val_data\\\\', '*.csv'))\n",
    "    for file in csv_files:\n",
    "        os.remove(file)\n",
    "\n",
    "    csv_files = glob.glob(os.path.join('model_data\\\\train_data\\\\', '*.csv'))\n",
    "    for file in csv_files:\n",
    "        os.remove(file)\n",
    "\n",
    "    random.seed(45)\n",
    "        \n",
    "    #Get tickers in acl18 dataset and divide it in 50% test data, 50% validation data\n",
    "    table_df = pd.read_csv('tick_lst/acl18.txt', sep='\\t')\n",
    "    table_lst = table_df.Symbol.to_list()\n",
    "    valtick_lst = random.sample(table_lst , 44)\n",
    "    testtick_lst = list()\n",
    "    \n",
    "    #Save files into test and validation folders\n",
    "    for tick in table_lst:\n",
    "        raw_df = pd.read_csv(f'acl18/raw/{tick[1:]}.csv')\n",
    "        df = raw_df[(raw_df.Date >= '2014-01-01') & (raw_df.Date <= '2016-12-31') ]\n",
    "        df.dropna(inplace = True) #drop tickers that have missing data within date range\n",
    "        Ldf = len(df)\n",
    "        if tick in valtick_lst and df.Low.min()>= 1.0 and df.Volume.min()>= 500.0 and len(df)>= L:\n",
    "            df.to_csv(f'model_data/val_data/{tick[1:]}.csv')\n",
    "        elif df.Low.min()>= 1.0 and df.Volume.min()>= 500.0 and len(df)>= L:\n",
    "            testtick_lst.append(tick)\n",
    "            df.to_csv(f'model_data/test_data/{tick[1:]}.csv')\n",
    "        else:\n",
    "            #Only select tickers that have data covering the entire date range\n",
    "            pass\n",
    "\n",
    "    #Save files into training folder\n",
    "    #Added additional preprocessing\n",
    "    #1. Eliminate tickers in validation and test sets\n",
    "    #2. Eliminate tickers if daily trading volume falls below 10000 (ensures sufficient trading volume)\n",
    "    #3. Eliminate tickers if low price falls below $5 (ensures sufficient trading volume)\n",
    "    #4. Eliminate tickers that have less than L datapoints\n",
    "    traintick_lst = list()\n",
    "    for fle in glob.glob(\"tick_data/*.csv\"):\n",
    "        fsplt = '$'+ fle.split('\\\\')[1]\n",
    "        tick = fsplt.rpartition('.')[0]\n",
    "\n",
    "        if tick not in table_lst:\n",
    "            raw_df = pd.read_csv(f'tick_data/{tick[1:]}.csv')\n",
    "                   \n",
    "            df = raw_df[(raw_df['Date'] >= '2014-01-01') & (raw_df['Date'] <= '2016-12-31') ]\n",
    "            if df.Low.min()>= 1.0 and df.Volume.min()>= 500.0 and len(df)>= L: \n",
    "                traintick_lst.append(tick)\n",
    "                df.to_csv(f'model_data/train_data/{tick[1:]}.csv')\n",
    "\n",
    "def create_lag(arry, lag = 5):\n",
    "    \"\"\"\n",
    "    Create lagged features\n",
    "\n",
    "    Parameters:\n",
    "    array (numpy array): A numpy array from which to create features\n",
    "    lag (int, optional): Lag value for features. Default is 5. \n",
    "\n",
    "    Returns:\n",
    "    Numpy array with lag features. The last element in the features is the truth label\n",
    "    (arry[:,:,-1] is truth label)\n",
    "    \"\"\"    \n",
    "\n",
    "    for t in range(0,lag):\n",
    "        arry = np.concatenate((arry[:,:-1,0:16],arry[:,1:,:]), axis = 2 )\n",
    "    return arry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rsi(data, period=14):\n",
    "    \"\"\"\n",
    "    Calculates the Relative Strength Index (RSI) for a given Pandas Series of closing prices.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.Series): A Pandas Series representing the closing prices of an asset.\n",
    "    period (int, optional): The period over which to calculate the RSI. Default is 14.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A Pandas Series containing the RSI values.\n",
    "    \"\"\"\n",
    "    delta = data.diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "    avg_gain = gain.rolling(window=period, min_periods=period).mean()\n",
    "    avg_loss = loss.rolling(window=period, min_periods=period).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "\n",
    "def calculate_bollinger_bands_percent(data, period=20, sigma=2):\n",
    "    \"\"\"\n",
    "    Calculates the Bollinger Bands Percentage (%B) for a given Pandas Series of closing prices.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.Series): A Pandas Series representing the closing prices of an asset.\n",
    "    period (int, optional): The period over which to calculate the %B. Default is 20.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A Pandas Series containing the %B values.\n",
    "    \"\"\"\n",
    "    rolling_avg = data.rolling(period).mean()\n",
    "    rolling_std = data.rolling(period).std()\n",
    "    upper = rolling_avg + sigma * rolling_std\n",
    "    lower = rolling_avg - sigma * rolling_std\n",
    "    return (data - lower) / (upper - lower)\n",
    "\n",
    "\n",
    "def calculate_stochastic_momentum_indicator(data, k_period=5, d_period=10, signal_period=5):\n",
    "    \"\"\"\n",
    "    Calculates the Stochastic Momentum Indicator (SMI) for a given Pandas Series of closing prices.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.Series): A Pandas Series representing the closing prices of an asset.\n",
    "    period (int, optional): The period over which to calculate the SMI. Default is 20.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A Pandas Series containing the %B values.\n",
    "    \"\"\"\n",
    "    # https://www.tradingview.com/support/solutions/43000707882-stochastic-momentum-index-smi/\n",
    "    # https://www.amcharts.com/stochastic-momentum-index-indicator/\n",
    "    delta = data.rolling(k_period).max() - data.rolling(k_period).min()\n",
    "    relative = data - (data.rolling(k_period).max() + data.rolling(k_period).min()) / 2\n",
    "    delta = delta.ewm(span=d_period, adjust=False).mean().ewm(span=d_period, adjust=False).mean()\n",
    "    relative = relative.ewm(span=d_period, adjust=False).mean().ewm(span=d_period, adjust=False).mean()\n",
    "    smi = 100 * (relative / delta)\n",
    "    signal = smi.ewm(span=signal_period, adjust=False).mean()\n",
    "    return smi, signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code does several things\n",
    "# 1. It gets all the tickers that has 2767 datapoints\n",
    "# 2. It calculates the following indicates for each ticker (20 and 100 day EMA, MACD, RSI, CCI, BOLL, MA5/MA10, MTM6/MTM12, ROC, SMI)\n",
    "# 3. In order to scale all ticker share prices to the same range, it takes the difference between the consecutive days (e.g., RSI(t) - RSI (t-1))\n",
    "# 4. It takes the log of the differences\n",
    "# 5. It normalizes the open, high, low, and close price by the previous day's close price and take the log value ensuring the normalized share prices for all tickers are in the same range for training stability\n",
    "# 6. It normalizes the volume by the previous day's volume and take the log value\n",
    "# 7. It calculates the labels (Change), which is whether the close price increases(1) or decreases(0) the next day\n",
    "# 8. It converts everything to a numpy array and concatenate the array on each loop\n",
    "# Final numpy array is shape (Ntickers, Ndays, Nfeatures)\n",
    "# Ntickers = number of tickers\n",
    "# Ndays = number of days\n",
    "# Nfeatures = number of features + 1 truth label\n",
    "# Features+label are EMA20dif, EMA100dif, RSIdif, MACDdif, Opendif, Highdif, Lowdif, Closedif, Volumedif, Change\n",
    "# 'dif' indicates the normarlize value (e.g., EMA20dif)\n",
    "# Ignore runtime warning\n",
    "\n",
    "def return_numpy_data(flepth):\n",
    "    \"\"\"\n",
    "    Calculates the features and truth label for the model\n",
    "\n",
    "    Parameters:\n",
    "    str: file path to location of csv data files\n",
    "\n",
    "    Returns:\n",
    "    tensor: A numpy array containing the features and the truth label. The truth label is index [-1]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        del ticker_ary\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #loop through all the tickers\n",
    "    for fle in glob.glob(f\"{flepth}/*.csv\"):\n",
    "\n",
    "        ticker_df = pd.read_csv(f'{fle}')\n",
    "        ticker_temp2 = ticker_df.copy()\n",
    "        \n",
    "        #calculate the technical indicators\n",
    "        indicators = ['EMA20','EMA100', 'RSI', 'MACD','MACDSignal', 'CCI', 'BOLL', 'MA5_MA10', 'MTM6_MTM12', 'ROC', 'SMI']\n",
    "        \n",
    "        # EMAs and MACD\n",
    "        ticker_temp2['EMA12'] = ticker_temp2['Close'].ewm(span=12, adjust=False).mean()\n",
    "        ticker_temp2['EMA26'] = ticker_temp2['Close'].ewm(span=26, adjust=False).mean()\n",
    "        ticker_temp2['EMA20'] = ticker_temp2['Close'].ewm(span=20, adjust=False).mean()\n",
    "        ticker_temp2['EMA100'] = ticker_temp2['Close'].ewm(span=100, adjust=False).mean()\n",
    "        ticker_temp2['MACD'] = ticker_temp2['EMA12'] - ticker_temp2['EMA26']\n",
    "        ticker_temp2['MACDSignal'] = ticker_temp2['MACD'].ewm(span=9, adjust=False).mean()\n",
    "        \n",
    "        # RSI\n",
    "        ticker_temp2['RSI'] = calculate_rsi(ticker_temp2['Close'])\n",
    "\n",
    "        # CCI\n",
    "        ticker_temp2['p_t'] = (ticker_temp2['High'] + ticker_temp2['Low'] + ticker_temp2['Close']) / 3\n",
    "        ticker_temp2['p_t_MAD'] = (ticker_temp2['p_t'] - ticker_temp2['p_t'].rolling(20).mean()).abs().mean() \n",
    "        ticker_temp2['CCI'] = (ticker_temp2['p_t'] - ticker_temp2['p_t'].rolling(20).mean()) / (0.015 * ticker_temp2['p_t_MAD'])\n",
    "\n",
    "        # ATR\n",
    "        ticker_temp2['Close_shift1'] = ticker_temp2['Close'].shift(1)\n",
    "        ticker_temp2['TR'] = ticker_temp2[['High', 'Close_shift1']].max(axis=1) - ticker_temp2[['Low', 'Close_shift1']].min(axis=1)\n",
    "        ticker_temp2['ATR'] = ticker_temp2['TR'].ewm(span=10, adjust=False).mean()\n",
    "\n",
    "        # BOLL\n",
    "        ticker_temp2['BOLL'] = calculate_bollinger_bands_percent(ticker_temp2['Close'])\n",
    "\n",
    "        # MA5/MA10\n",
    "        ticker_temp2['MA5'] = ticker_temp2['Close'].rolling(5).mean()\n",
    "        ticker_temp2['MA10'] = ticker_temp2['Close'].rolling(10).mean()\n",
    "        ticker_temp2['MA5_MA10'] = ticker_temp2['MA5'] / ticker_temp2['MA10']\n",
    "\n",
    "        # MTM6/MTM12\n",
    "        ticker_temp2['MTM6'] = ticker_temp2['Close'] / ticker_temp2['Close'].shift(6)\n",
    "        ticker_temp2['MTM12'] = ticker_temp2['Close'] / ticker_temp2['Close'].shift(12)\n",
    "        ticker_temp2['MTM6_MTM12'] = ticker_temp2['MTM6'] / ticker_temp2['MTM12']\n",
    "\n",
    "        # ROC\n",
    "        ticker_temp2['ROC'] = 100 * (ticker_temp2['Close'] - ticker_temp2['Close'].shift(10)) / ticker_temp2['Close'].shift(10)\n",
    "\n",
    "        # SMI\n",
    "        ticker_temp2['SMI'], ticker_temp2['SMI_signal'] = calculate_stochastic_momentum_indicator(ticker_temp2['Close'])\n",
    "\n",
    "        # normalize the technical indicators\n",
    "        for i in indicators:\n",
    "            ticker_temp2[i+'dif'] = (ticker_temp2[i] + eps) / (ticker_temp2[i].shift(1) + eps)\n",
    "        ticker_log = ticker_temp2[[i+'dif' for i in indicators]]\n",
    "\n",
    "\n",
    "        #normalize the share prices and volume (OHLCV)\n",
    "        ticker_log['Opendif'] = ticker_temp2['Open']/ticker_temp2['Close'].shift(1)\n",
    "        ticker_log['Highdif'] = ticker_temp2['High']/ticker_temp2['Close'].shift(1)\n",
    "        ticker_log['Lowdif'] = ticker_temp2['Low']/ticker_temp2['Close'].shift(1)\n",
    "        ticker_log['Closedif'] = ticker_temp2['Close']/ticker_temp2['Close'].shift(1)\n",
    "        ticker_log['Volumedif']  = ticker_temp2['Volume']/ticker_temp2['Volume'].shift(1)\n",
    "\n",
    "\n",
    "        #Calculate the label for each day\n",
    "        ticker_log['Truth_lbl'] = ticker_temp2['Close'].shift(-1)/ticker_temp2['Close']\n",
    "        ticker_log.dropna(inplace = True)\n",
    "        \n",
    "        #Convert to a numpy array\n",
    "        ticker_temp = ticker_log.values\n",
    "\n",
    "        #Add new ticker data to numpy array as we loop through the data\n",
    "        try:\n",
    "            ticker_ary  = np.concatenate((ticker_ary, ticker_temp[np.newaxis, :, :]), axis=0)  \n",
    "        except:\n",
    "            ticker_ary = ticker_temp[np.newaxis, :, :]\n",
    "            \n",
    "        del ticker_temp\n",
    "       \n",
    "    return ticker_ary\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training, test, and val arrays are created\n",
      "---------------\n",
      "\n",
      "Array shape is (N_tickers, N_trading_days, N_features + label)\n",
      "There are 96 features and 1 label\n",
      "Label is array[:,:,-1], N_features are array[:,:,:-1]\n",
      "---------------\n",
      "\n",
      "train data shape: (333, 730, 97)\n",
      "test data shape: (40, 730, 97)\n",
      "val data shape: (40, 730, 97)\n"
     ]
    }
   ],
   "source": [
    "#Split the data into train, val, test\n",
    "splitdata()\n",
    "\n",
    "#Create the features for the train, val, test datasets\n",
    "train_ary = return_numpy_data('model_data\\\\train_data\\\\')\n",
    "val_ary = return_numpy_data('model_data\\\\val_data\\\\')\n",
    "test_ary = return_numpy_data('model_data\\\\test_data\\\\')\n",
    "\n",
    "#Create lag features\n",
    "train_ary = create_lag(train_ary, lag = 5)\n",
    "val_ary = create_lag(val_ary, lag = 5)\n",
    "test_ary = create_lag(test_ary, lag = 5)\n",
    "\n",
    "\n",
    "print(\"training, test, and val arrays are created\")\n",
    "print('---------------\\n')\n",
    "\n",
    "print(\"Array shape is (N_tickers, N_trading_days, N_features + label)\")\n",
    "print(\"There are 96 features and 1 label\")\n",
    "print('Label is array[:,:,-1], N_features are array[:,:,:-1]')\n",
    "print('---------------\\n')\n",
    "\n",
    "print(\"train data shape:\", train_ary.shape)\n",
    "print(\"test data shape:\", test_ary.shape)\n",
    "print(\"val data shape:\", val_ary.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
