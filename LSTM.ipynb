{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5611bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from models.StackedAutoEncoder import SimpleAutoEncoder, AutoEncoder, StackedAutoEncoder\n",
    "from models.LSTM import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e047286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close Price</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MACD</th>\n",
       "      <th>CCI</th>\n",
       "      <th>ATR</th>\n",
       "      <th>BOLL</th>\n",
       "      <th>EMA20</th>\n",
       "      <th>MA10</th>\n",
       "      <th>MTM6</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MTM12</th>\n",
       "      <th>ROC</th>\n",
       "      <th>SMI</th>\n",
       "      <th>WVAD</th>\n",
       "      <th>US Dollar Index</th>\n",
       "      <th>Federal Fund Rate</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.981796</td>\n",
       "      <td>1.007151</td>\n",
       "      <td>1.005337</td>\n",
       "      <td>1.000658</td>\n",
       "      <td>0.902468</td>\n",
       "      <td>1.079324</td>\n",
       "      <td>0.909298</td>\n",
       "      <td>1.244823</td>\n",
       "      <td>0.996465</td>\n",
       "      <td>0.995270</td>\n",
       "      <td>0.994167</td>\n",
       "      <td>1.594742</td>\n",
       "      <td>0.990626</td>\n",
       "      <td>1.312833</td>\n",
       "      <td>1.312727</td>\n",
       "      <td>1.531305</td>\n",
       "      <td>1.379623</td>\n",
       "      <td>0.995162</td>\n",
       "      <td>0.924171</td>\n",
       "      <td>1.001094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.001094</td>\n",
       "      <td>0.982221</td>\n",
       "      <td>0.983988</td>\n",
       "      <td>0.992469</td>\n",
       "      <td>0.615530</td>\n",
       "      <td>1.042193</td>\n",
       "      <td>0.994015</td>\n",
       "      <td>0.635029</td>\n",
       "      <td>0.996334</td>\n",
       "      <td>0.995799</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>1.119386</td>\n",
       "      <td>0.996830</td>\n",
       "      <td>0.892618</td>\n",
       "      <td>0.898704</td>\n",
       "      <td>0.689579</td>\n",
       "      <td>1.067612</td>\n",
       "      <td>1.010279</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.991615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.991615</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>1.001943</td>\n",
       "      <td>0.990951</td>\n",
       "      <td>1.621332</td>\n",
       "      <td>1.049721</td>\n",
       "      <td>0.966405</td>\n",
       "      <td>1.708783</td>\n",
       "      <td>0.995803</td>\n",
       "      <td>0.995417</td>\n",
       "      <td>0.994922</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.995906</td>\n",
       "      <td>0.971260</td>\n",
       "      <td>1.034488</td>\n",
       "      <td>1.193649</td>\n",
       "      <td>0.963357</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>1.036458</td>\n",
       "      <td>1.017080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.017080</td>\n",
       "      <td>0.991242</td>\n",
       "      <td>1.000173</td>\n",
       "      <td>1.001741</td>\n",
       "      <td>1.145988</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.743315</td>\n",
       "      <td>0.941689</td>\n",
       "      <td>0.996342</td>\n",
       "      <td>0.997390</td>\n",
       "      <td>0.996555</td>\n",
       "      <td>0.241657</td>\n",
       "      <td>0.999007</td>\n",
       "      <td>0.808538</td>\n",
       "      <td>0.497853</td>\n",
       "      <td>0.619646</td>\n",
       "      <td>0.730327</td>\n",
       "      <td>1.003438</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.977224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.977224</td>\n",
       "      <td>1.017207</td>\n",
       "      <td>1.002504</td>\n",
       "      <td>1.001392</td>\n",
       "      <td>0.858619</td>\n",
       "      <td>1.042824</td>\n",
       "      <td>1.119407</td>\n",
       "      <td>1.046601</td>\n",
       "      <td>0.995914</td>\n",
       "      <td>0.995517</td>\n",
       "      <td>0.994568</td>\n",
       "      <td>6.384127</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>1.059453</td>\n",
       "      <td>1.657384</td>\n",
       "      <td>1.892856</td>\n",
       "      <td>1.305448</td>\n",
       "      <td>0.994929</td>\n",
       "      <td>1.010152</td>\n",
       "      <td>1.006990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Close Price  Open Price  High Price  Low Price    Volume      MACD  \\\n",
       "1     0.981796    1.007151    1.005337   1.000658  0.902468  1.079324   \n",
       "2     1.001094    0.982221    0.983988   0.992469  0.615530  1.042193   \n",
       "3     0.991615    0.999952    1.001943   0.990951  1.621332  1.049721   \n",
       "4     1.017080    0.991242    1.000173   1.001741  1.145988  0.969146   \n",
       "5     0.977224    1.017207    1.002504   1.001392  0.858619  1.042824   \n",
       "\n",
       "        CCI       ATR      BOLL     EMA20      MA10      MTM6       MA5  \\\n",
       "1  0.909298  1.244823  0.996465  0.995270  0.994167  1.594742  0.990626   \n",
       "2  0.994015  0.635029  0.996334  0.995799  0.993853  1.119386  0.996830   \n",
       "3  0.966405  1.708783  0.995803  0.995417  0.994922  0.441341  0.995906   \n",
       "4  0.743315  0.941689  0.996342  0.997390  0.996555  0.241657  0.999007   \n",
       "5  1.119407  1.046601  0.995914  0.995517  0.994568  6.384127  0.993651   \n",
       "\n",
       "      MTM12       ROC       SMI      WVAD  US Dollar Index  Federal Fund Rate  \\\n",
       "1  1.312833  1.312727  1.531305  1.379623         0.995162           0.924171   \n",
       "2  0.892618  0.898704  0.689579  1.067612         1.010279           0.984615   \n",
       "3  0.971260  1.034488  1.193649  0.963357         0.999725           1.036458   \n",
       "4  0.808538  0.497853  0.619646  0.730327         1.003438           0.989950   \n",
       "5  1.059453  1.657384  1.892856  1.305448         0.994929           1.010152   \n",
       "\n",
       "     target  \n",
       "1  1.001094  \n",
       "2  0.991615  \n",
       "3  1.017080  \n",
       "4  0.977224  \n",
       "5  1.006990  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(Path(\"RawData.xlsx\"), \"S&P500 Index Data\")\n",
    "features = list(data.columns[2:])\n",
    "data[features] = data[features] / data[features].shift(1)\n",
    "data.dropna(inplace=True)\n",
    "train = data.loc[(data['Ntime'] >= 20120101) & (data['Ntime'] < 20140101)]\n",
    "val = data.loc[(data['Ntime'] >= 20140101) & (data['Ntime'] < 20140401)]\n",
    "test = data.loc[(data['Ntime'] >= 20140401) & (data['Ntime'] < 20140701)]\n",
    "data = data[features]\n",
    "data['target'] = data['Close Price'].shift(-1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61237648",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train.npy\", train)\n",
    "np.save(\"val.npy\", val)\n",
    "np.save(\"test.npy\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a10197c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([482, 19, 21])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(stock, lookback):\n",
    "    data_raw = stock.to_numpy()\n",
    "    data = []\n",
    "    for index in range(len(data_raw) - lookback): \n",
    "        data.append(data_raw[index: index + lookback])\n",
    "    data = np.array(data)\n",
    "    x = data[:, :-1]\n",
    "    y = data[:, -1, :]\n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = split_data(train, lookback=20)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fac20d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christian/anaconda3/envs/a3/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([482, 21])) that is different to the input size (torch.Size([482, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss:  19313918476288.0\n",
      "Epoch  1 Loss:  19313916379136.0\n",
      "Epoch  2 Loss:  19313910087680.0\n",
      "Epoch  3 Loss:  19313905893376.0\n",
      "Epoch  4 Loss:  19313905893376.0\n",
      "Epoch  5 Loss:  19313903796224.0\n",
      "Epoch  6 Loss:  19313903796224.0\n",
      "Epoch  7 Loss:  19313899601920.0\n",
      "Epoch  8 Loss:  19313895407616.0\n",
      "Epoch  9 Loss:  19313895407616.0\n",
      "Epoch  10 Loss:  19313891213312.0\n",
      "Epoch  11 Loss:  19313889116160.0\n",
      "Epoch  12 Loss:  19313889116160.0\n",
      "Epoch  13 Loss:  19313880727552.0\n",
      "Epoch  14 Loss:  19313880727552.0\n",
      "Epoch  15 Loss:  19313880727552.0\n",
      "Epoch  16 Loss:  19313876533248.0\n",
      "Epoch  17 Loss:  19313872338944.0\n",
      "Epoch  18 Loss:  19313872338944.0\n",
      "Epoch  19 Loss:  19313866047488.0\n",
      "Epoch  20 Loss:  19313861853184.0\n",
      "Epoch  21 Loss:  19313861853184.0\n",
      "Epoch  22 Loss:  19313861853184.0\n",
      "Epoch  23 Loss:  19313853464576.0\n",
      "Epoch  24 Loss:  19313853464576.0\n",
      "Epoch  25 Loss:  19313851367424.0\n",
      "Epoch  26 Loss:  19313849270272.0\n",
      "Epoch  27 Loss:  19313849270272.0\n",
      "Epoch  28 Loss:  19313845075968.0\n",
      "Epoch  29 Loss:  19313838784512.0\n",
      "Epoch  30 Loss:  19313838784512.0\n",
      "Epoch  31 Loss:  19313836687360.0\n",
      "Epoch  32 Loss:  19313830395904.0\n",
      "Epoch  33 Loss:  19313830395904.0\n",
      "Epoch  34 Loss:  19313826201600.0\n",
      "Epoch  35 Loss:  19313824104448.0\n",
      "Epoch  36 Loss:  19313824104448.0\n",
      "Epoch  37 Loss:  19313819910144.0\n",
      "Epoch  38 Loss:  19313813618688.0\n",
      "Epoch  39 Loss:  19313813618688.0\n",
      "Epoch  40 Loss:  19313809424384.0\n",
      "Epoch  41 Loss:  19313809424384.0\n",
      "Epoch  42 Loss:  19313809424384.0\n",
      "Epoch  43 Loss:  19313803132928.0\n",
      "Epoch  44 Loss:  19313798938624.0\n",
      "Epoch  45 Loss:  19313798938624.0\n",
      "Epoch  46 Loss:  19313796841472.0\n",
      "Epoch  47 Loss:  19313792647168.0\n",
      "Epoch  48 Loss:  19313792647168.0\n",
      "Epoch  49 Loss:  19313786355712.0\n",
      "Epoch  50 Loss:  19313782161408.0\n",
      "Epoch  51 Loss:  19313782161408.0\n",
      "Epoch  52 Loss:  19313780064256.0\n",
      "Epoch  53 Loss:  19313773772800.0\n",
      "Epoch  54 Loss:  19313773772800.0\n",
      "Epoch  55 Loss:  19313771675648.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10_000\u001b[39m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTM(input_size\u001b[38;5;241m=\u001b[39minput_size, hidden_size\u001b[38;5;241m=\u001b[39mhidden_size, num_layers\u001b[38;5;241m=\u001b[39mnum_layers, output_size\u001b[38;5;241m=\u001b[39moutput_size, dropout\u001b[38;5;241m=\u001b[39mdropout)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/CS7643/models/LSTM.py:36\u001b[0m, in \u001b[0;36mLSTM.fit\u001b[0;34m(self, x, y, epochs, lr)\u001b[0m\n\u001b[1;32m     34\u001b[0m hist[t] \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     35\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 36\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/a3/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/a3/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_size = 1\n",
    "hidden_size = 32\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "dropout = 0.2\n",
    "num_epochs = 10_000\n",
    "\n",
    "model = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size, dropout=dropout)\n",
    "model.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
